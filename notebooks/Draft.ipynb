{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825733ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bae8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "from Levenshtein import distance as levenshtein_distance_function\n",
    "\n",
    "class EditType(Enum):\n",
    "    none = 0\n",
    "    insert = 1\n",
    "    replace = 2\n",
    "    delete = 3\n",
    "    transpose = 4\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        self.value < other.value\n",
    "        \n",
    "    def probability(self):\n",
    "        \"\"\"\n",
    "            A paper by Kukich (1992) suggested the following\n",
    "            error rates based on an analysis of spelling errors\n",
    "            in various databases:\n",
    "\n",
    "            Substitution errors: 80%\n",
    "            Deletion errors: 10%\n",
    "            Insertion errors: 5%\n",
    "            Transposition errors: 5%\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        if self == EditType.none:\n",
    "            return 0\n",
    "        elif self == EditType.insert:\n",
    "            return 0.05\n",
    "        elif self == EditType.replace:\n",
    "            return 0.8\n",
    "        elif self == EditType.delete:\n",
    "            return 0.1\n",
    "        else:\n",
    "            return 0.05\n",
    "\n",
    "class Edit:\n",
    "\n",
    "    def __init__(self, \n",
    "                 word, \n",
    "                 edit,\n",
    "                 edit_type: EditType,\n",
    "                 edit_word_probability,\n",
    "                 keyboard_distance,\n",
    "                 prev_edit = None):\n",
    "        self.word = word # the misspelled word\n",
    "        self.edit = edit # the edit that would fix the misspelled word\n",
    "        self.edit_type = edit_type # edit type, refer to the enum above\n",
    "        self.prev_edit = prev_edit # reference to the previous edit, if any\n",
    "        self.edit_word_probability = edit_word_probability # the probability of the suggested edit to occur in the whole text curpus\n",
    "        self.keyboard_distance = keyboard_distance # for example, if edit_type is replace, keyboard_distance is the manhattan distance between the correct and wrong letters on a qwerty layout keyabord\n",
    "        self.levenshtein_distance = levenshtein_distance_function(word, edit)\n",
    "        \n",
    "    def __hash__(self):\n",
    "        return hash((self.edit, self.edit_type))\n",
    "\n",
    "    def __eq__(self,other):\n",
    "        return self.edit == other.edit and self.edit_type == other.edit_type\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"\"\"\n",
    "        Edit of\n",
    "            content = {self.word}\n",
    "            edit = {self.edit}\n",
    "            type = {self.edit_type.name}\n",
    "            edit word probaility = {self.edit_word_probability}\n",
    "            keyboard_distance = {self.keyboard_distance}\n",
    "            levenshtein distance = {self.levenshtein_distance}\n",
    "            previous edit = \n",
    "                {self.prev_edit}\n",
    "        \"\"\"\n",
    "    \n",
    "    def probability(self, keyboard_weight = 1.0, edit_type_weight = 0.1, word_probability_weight = 20.0):\n",
    "        # Scale the distances and probabilities so they have similar magnitudes.\n",
    "        keyboard_distance_score = 1 / (1 + self.keyboard_distance + self.levenshtein_distance) ** keyboard_weight\n",
    "        edit_type_probability = self.edit_type.probability() ** edit_type_weight\n",
    "        word_probability = self.edit_word_probability ** word_probability_weight\n",
    "\n",
    "        # Combine them using multiplication: this will return high probability only if all factors are high.\n",
    "        combined_probability = keyboard_distance_score * edit_type_probability * word_probability\n",
    "        return combined_probability\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d82409d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from core.constants import keyboard_letters, neighbour_letters, keyboard_layouts\n",
    "\n",
    "class SpellChecker:\n",
    "    \n",
    "    def __init__(self, language = \"en\", override_file = None):\n",
    "        \n",
    "        if override_file:\n",
    "            file_to_open = override_file\n",
    "        else:\n",
    "            file_to_open = f'texts/big_{language}.txt'\n",
    "        \n",
    "        with open(file_to_open, \"r\") as file:\n",
    "            raw_text = file.read()\n",
    "            raw_words = re.findall(r'\\w+', raw_text.lower())\n",
    "            self.WORDS = Counter(raw_words)\n",
    "        \n",
    "        self.N = sum(self.WORDS.values())\n",
    "        self.letters = keyboard_letters[language]\n",
    "        self.neighbour_letters = neighbour_letters[language]\n",
    "        self.keyboard_layout = keyboard_layouts[language]\n",
    "        \n",
    "    def keyboard_distance(self, key1, key2):\n",
    "\n",
    "        key_coordinates = {}\n",
    "\n",
    "        for i, row in enumerate(self.keyboard_layout):\n",
    "            for j, key in enumerate(row):\n",
    "                key_coordinates[key] = (i, j)\n",
    "\n",
    "        if key1 not in key_coordinates or key2 not in key_coordinates:\n",
    "            return 0\n",
    "\n",
    "        x1, y1 = key_coordinates[key1]\n",
    "        x2, y2 = key_coordinates[key2]\n",
    "\n",
    "        return abs(x1 - x2) + abs(y1 - y2)\n",
    "        \n",
    "    def P(self, word): \n",
    "        \"Probability of `word`.\"\n",
    "        \n",
    "        # first sort by probability, then sort by edit_type, then sort by keyboard distance, if any\n",
    "        return self.WORDS[word] / self.N\n",
    "\n",
    "    def correction(self, word): \n",
    "        \"Most probable spelling correction for word.\"\n",
    "        \n",
    "        # correction is defined as following:\n",
    "        candidates = list(self.candidates(word))\n",
    "        \n",
    "        candidates.sort(key = lambda x: self.P(x), reverse = True)\n",
    "        candidates.sort(key = lambda x: x.keyboard_distance)\n",
    "        candidates.sort(key = lambda x: x.edit_type.value)\n",
    "        \n",
    "        return candidates[0]\n",
    "\n",
    "    def candidates(self, word): \n",
    "        \"Generate possible spelling corrections for word.\"\n",
    "        return (self.known([Edit(word, word, EditType.none, 0, 0)]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [Edit(word, word, EditType.none, 0, 0)])\n",
    "\n",
    "    def known(self, edits): \n",
    "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "        return set(w for w in edits if w.edit in self.WORDS)\n",
    "\n",
    "    def edits1(self, word, prev_edit: Edit = None):\n",
    "        \"All edits that are one edit away from `word`.\"\n",
    "        splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "        \n",
    "        deletes    = set(self.__edits_deletes(word, splits, prev_edit))\n",
    "        transposes = set(self.__edits_transposes(word, splits, prev_edit))\n",
    "        replaces   = set(self.__edits_replaces(word, splits, prev_edit))\n",
    "        inserts    = set(self.__edits_inserts(word, splits, prev_edit))\n",
    "        all_set = deletes.union(transposes).union(replaces).union(inserts)\n",
    "        print([i.edit for i in replaces])\n",
    "        \n",
    "        return all_set\n",
    "\n",
    "    def edits2(self, word): \n",
    "        \"All edits that are two edits away from `word`.\"\n",
    "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1.edit, prev_edit = e1))\n",
    "    \n",
    "    def __edits_transposes(self, word, splits, prev_edit: Edit):\n",
    "        for L, R in splits:\n",
    "            if len(R) > 1:\n",
    "                edit_word = L + R[1] + R[0] + R[2:]\n",
    "                yield Edit(\n",
    "                    word = word, \n",
    "                    edit = edit_word,\n",
    "                    edit_type = EditType.transpose,\n",
    "                    prev_edit = prev_edit, \n",
    "                    edit_word_probability = self.P(edit_word),\n",
    "                    keyboard_distance = 1\n",
    "                )\n",
    "    \n",
    "    def __edits_inserts(self, word, splits, prev_edit: Edit):\n",
    "        for L, R in splits:\n",
    "            for c in self.letters:\n",
    "                \n",
    "                # Left's distance\n",
    "                if len(L) > 0:\n",
    "                    left = L[-1]\n",
    "                    L_distance = self.keyboard_distance(left, c)\n",
    "                else:\n",
    "                    L_distance = -1\n",
    "                \n",
    "                edit_word = L + c + R\n",
    "                yield Edit(\n",
    "                    word = word,\n",
    "                    edit = edit_word,\n",
    "                    edit_type = EditType.insert,\n",
    "                    prev_edit = prev_edit,\n",
    "                    edit_word_probability = self.P(edit_word),\n",
    "                    keyboard_distance = L_distance)\n",
    "    \n",
    "    def __edits_deletes(self, word, splits, prev_edit: Edit):\n",
    "        for L, R in splits:\n",
    "            if R:\n",
    "                omitted = R[0]\n",
    "                \n",
    "                # Left's distance\n",
    "                if len(L) > 0:\n",
    "                    left = L[-1]\n",
    "                    L_distance = self.keyboard_distance(left, omitted)\n",
    "                else:\n",
    "                    L_distance = -1\n",
    "                    \n",
    "                # Left's distance\n",
    "                if len(R) > 0:\n",
    "                    right = R[-1]\n",
    "                    R_distance = self.keyboard_distance(right, omitted)\n",
    "                else:\n",
    "                    R_distance = -1\n",
    "                \n",
    "                key_distance = min(L_distance, R_distance)\n",
    "                edit_word = L + R[1:]\n",
    "                yield Edit(\n",
    "                    word = word,\n",
    "                    edit = edit_word,\n",
    "                    edit_type = EditType.delete,\n",
    "                    prev_edit = prev_edit, \n",
    "                    edit_word_probability = self.P(edit_word),\n",
    "                    keyboard_distance = key_distance\n",
    "                )\n",
    "    \n",
    "    def __edits_replaces(self, word, splits, prev_edit: Edit):\n",
    "        for L, R in splits:\n",
    "            if R:\n",
    "                for c in self.letters:\n",
    "                    \n",
    "                    omitted = R[0]\n",
    "                    key_distance = self.keyboard_distance(c, omitted)\n",
    "                    edit_word = L + c + R[1:]\n",
    "                    yield Edit(\n",
    "                        word = word, \n",
    "                        edit = edit_word,\n",
    "                        edit_type = EditType.replace, \n",
    "                        prev_edit = prev_edit,\n",
    "                        edit_word_probability = self.P(edit_word),\n",
    "                        keyboard_distance = key_distance\n",
    "                    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e03ecbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = [\"տետր\", \"պատուհան\", \"Կարինե\", \"կարտոֆիլ\", \"գրիչ\", \"անհավանական\", \"քննություն\", \"արհեստական\", \"բնական\", \"համակարգիչ\", \"մատիտ\", \"սեղան\", \"գրատախտակ\", \"ականջակալ\", \"քաղաք\", \"հանրապետություն\", \"թուղթ\", \"գրադարան\", \"վարձակալություն\", \"գրագետ\"]\n",
    "correct = [\"տետհ\", \"պատուեան\", \"ուարինե\", \"կարտոֆիլ\", \"գրիչ\", \"անհավանական\", \"քննություն\", \"արհեստական\", \"բնական\", \"համակարգիչ\", \"մատիտ\", \"սեղան\", \"գրատախտակ\", \"ականջակալ\", \"քաղաք\", \"հանրապետություն\", \"թուղթ\", \"գրադարան\", \"վարձակալություն\", \"գրագետ\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "950d483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker = SpellChecker(language = \"am\", override_file = \"../texts/big_am.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd0c9caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['քնէություլ', 'քննությոգլ', 'ոննություլ', 'քչնություլ', 'քննութծուլ', 'քղնություլ', 'քճնություլ', 'ւննություլ', 'փննություլ', 'քննոխթյուլ', 'քննզւթյուլ', 'քննոյթյուլ', 'քննություվ', 'քննություկ', 'քնմություլ', 'քննգւթյուլ', 'քննությոփլ', 'քննություփ', 'շննություլ', 'քննությում', 'քթնություլ', 'քննությորլ', 'քննություս', 'քնղություլ', 'քննութչուլ', 'քննությոծլ', 'քննությդւլ', 'քւնություլ', 'քննություպ', 'քննությզւլ', 'քննութձուլ', 'յննություլ', 'քհնություլ', 'քննությոիլ', 'քննփւթյուլ', 'քշնություլ', 'քննճւթյուլ', 'քննլւթյուլ', 'քննուբյուլ', 'քնկություլ', 'քննութւուլ', 'քնշություլ', 'քննությտւլ', 'քննոդթյուլ', 'քննուեյուլ', 'քննութիուլ', 'քննությրւլ', 'քննողթյուլ', 'քննություա', 'քննուֆյուլ', 'քննությււլ', 'քննոձթյուլ', 'քննություո', 'քննություգ', 'քնւություլ', 'քննությքւլ', 'քննուըյուլ', 'քննությոկլ', 'քննությոոլ', 'քննութնուլ', 'քննությռւլ', 'քննուվյուլ', 'քնբություլ', 'քնննւթյուլ', 'քննոհթյուլ', 'քննոեթյուլ', 'քննութօուլ', 'քննուճյուլ', 'քնրություլ', 'քննոճթյուլ', 'քննությոթլ', 'քննորթյուլ', 'քննությճւլ', 'քնքություլ', 'էննություլ', 'քննումյուլ', 'քնտություլ', 'քննոօթյուլ', 'քննոջթյուլ', 'քննէւթյուլ', 'քնփություլ', 'քննոըթյուլ', 'քննոչթյուլ', 'քննուջյուլ', 'քննությըւլ', 'քննունյուլ', 'քննուղյուլ', 'քննություե', 'օննություլ', 'քնյություլ', 'իննություլ', 'քննութըուլ', 'քնռություլ', 'քննություի', 'քնճություլ', 'քննություէ', 'քմնություլ', 'լննություլ', 'քննուգյուլ', 'քննությեւլ', 'քննոււյուլ', 'քխնություլ', 'քօնություլ', 'քնոություլ', 'քննություճ', 'քննութդուլ', 'քննդւթյուլ', 'քանություլ', 'քնֆություլ', 'քննուշյուլ', 'քննությհւլ', 'քնաություլ', 'քնդություլ', 'քննությոջլ', 'քննութտուլ', 'քննյւթյուլ', 'տննություլ', 'քննսւթյուլ', 'վննություլ', 'քնզություլ', 'քննութջուլ', 'քննոլթյուլ', 'ծննություլ', 'քէնություլ', 'քննոկթյուլ', 'քնլություլ', 'քննոֆթյուլ', 'րննություլ', 'քննությձւլ', 'ճննություլ', 'քննուժյուլ', 'քննցւթյուլ', 'քծնություլ', 'քննոռթյուլ', 'քննությնւլ', 'հննություլ', 'քզնություլ', 'քննությոնլ', 'քննութշուլ', 'քննությչւլ', 'քննուքյուլ', 'քննությոպլ', 'քննուայուլ', 'քննոէթյուլ', 'կննություլ', 'քննությոքլ', 'քննուէյուլ', 'քննույյուլ', 'քննություձ', 'քյնություլ', 'քննություր', 'քննոսթյուլ', 'քննությոժլ', 'քննությոձլ', 'քսնություլ', 'քնեություլ', 'քննութճուլ', 'քննութգուլ', 'քբնություլ', 'քննությթւլ', 'քննչւթյուլ', 'քննուցյուլ', 'քննությխւլ', 'քննությյւլ', 'քննպւթյուլ', 'քննություժ', 'մննություլ', 'քննութմուլ', 'քննութկուլ', 'քվնություլ', 'քննություզ', 'քննությոչլ', 'քննությոռլ', 'քոնություլ', 'քննուձյուլ', 'քննությոմլ', 'պննություլ', 'քդնություլ', 'քննությցւլ', 'քննոբթյուլ', 'քպնություլ', 'քննութէուլ', 'քնխություլ', 'քննութբուլ', 'քննություց', 'քննությոցլ', 'քննություտ', 'քննությոյլ', 'քննությիւլ', 'ցննություլ', 'քննովթյուլ', 'քննուկյուլ', 'քենություլ', 'քնվություլ', 'քձնություլ', 'քննությոէլ', 'քննությօւլ', 'քննություհ', 'քննււթյուլ', 'քննություն', 'քննությվւլ', 'քննոգթյուլ', 'քցնություլ', 'քննոտթյուլ', 'քննոաթյուլ', 'քննութժուլ', 'նննություլ', 'քնցություլ', 'ջննություլ', 'քննությժւլ', 'քննությմւլ', 'քփնություլ', 'քննութրուլ', 'քննուչյուլ', 'քննություւ', 'քննութպուլ', 'քննություչ', 'քննոժթյուլ', 'քննկւթյուլ', 'քննձւթյուլ', 'ղննություլ', 'քննաւթյուլ', 'քնթություլ', 'քննութփուլ', 'քննքւթյուլ', 'սննություլ', 'դննություլ', 'խննություլ', 'քննուոյուլ', 'քննությլւլ', 'քննութզուլ', 'քննություօ', 'քննոզթյուլ', 'քննուխյուլ', 'քննություջ', 'թննություլ', 'քննութհուլ', 'քննությոշլ', 'քնիություլ', 'քննռւթյուլ', 'քննութֆուլ', 'քջնություլ', 'քննություդ', 'քննուտյուլ', 'ըննություլ', 'ժննություլ', 'քննուզյուլ', 'քննությոօլ', 'քննոոթյուլ', 'զննություլ', 'քննությղւլ', 'քննութղուլ', 'քննությոսլ', 'քննություխ', 'քննեւթյուլ', 'քնհություլ', 'քննությոխլ', 'քննությփւլ', 'չննություլ', 'քննություլ', 'քննությոտլ', 'քննութքուլ', 'քինություլ', 'քննությոլլ', 'քննոմթյուլ', 'քննժւթյուլ', 'քննֆւթյուլ', 'քննությոհլ', 'գննություլ', 'քննությաւլ', 'քննությէւլ', 'քնսություլ', 'քննոցթյուլ', 'բննություլ', 'քննութթուլ', 'քննությկւլ', 'ձննություլ', 'քննուդյուլ', 'քննուիյուլ', 'քննթւթյուլ', 'քրնություլ', 'քննությոալ', 'քննոծթյուլ', 'քընություլ', 'ռննություլ', 'քննությծւլ', 'քննուփյուլ', 'քնըություլ', 'քննությոբլ', 'քննուհյուլ', 'քննրւթյուլ', 'քնպություլ', 'քննությգւլ', 'քննբւթյուլ', 'քննություծ', 'քննուօյուլ', 'քննօւթյուլ', 'քննությոզլ', 'քննությովլ', 'քնժություլ', 'քննոպթյուլ', 'քննծւթյուլ', 'քննիւթյուլ', 'քնձություլ', 'քննոփթյուլ', 'քլնություլ', 'քֆնություլ', 'քննոնթյուլ', 'քննությֆւլ', 'քննուսյուլ', 'քննություբ', 'քտնություլ', 'ֆննություլ', 'քննուպյուլ', 'քննուծյուլ', 'աննություլ', 'քննվւթյուլ', 'քննութեուլ', 'քննություշ', 'քժնություլ', 'քննությբւլ', 'քնջություլ', 'քնծություլ', 'քռնություլ', 'քննութխուլ', 'քննությոճլ', 'քննութռուլ', 'քննությսւլ', 'քննությոդլ', 'քննություռ', 'քննությոել', 'քննությշւլ', 'քննութոուլ', 'քննոքթյուլ', 'քննութվուլ', 'քննտւթյուլ', 'քննությոըլ', 'քննությույ', 'քննշւթյուլ', 'եննություլ', 'քննությպւլ', 'քննությողլ', 'քննություֆ', 'քննութցուլ', 'քննուլյուլ', 'քննութաուլ', 'քննոթթյուլ', 'քննըւթյուլ', 'քգնություլ', 'քննութսուլ', 'քննմւթյուլ', 'քննությոֆլ', 'քնգություլ', 'քննություղ', 'քննություք', 'քնօություլ', 'քնչություլ', 'քննոշթյուլ', 'քննուռյուլ', 'քննությութ', 'քկնություլ', 'քննութլուլ', 'քննղւթյուլ', 'քննհւթյուլ', 'քննխւթյուլ', 'քննոիթյուլ', 'քննություը', 'քքնություլ', 'քննջւթյուլ', 'քննությջւլ', 'քննուրյուլ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "        Edit of\n",
       "            content = քննություլ\n",
       "            edit = քննություն\n",
       "            type = replace\n",
       "            edit word probaility = 3.924292548160881e-06\n",
       "            keyboard_distance = 5\n",
       "            levenshtein distance = 1\n",
       "            previous edit = \n",
       "                None\n",
       "        "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correction(\"քննություլ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2bdc709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32198"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checker.WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7d1bc255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        Edit of\n",
       "            content = receit\n",
       "            edit = receipt\n",
       "            type = insert\n",
       "            edit word probaility = 1.1653078877898144e-05\n",
       "            keyboard_distance = 2\n",
       "            levenshtein distance = 1\n",
       "            previous edit = \n",
       "                None\n",
       "        "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correction(\"receit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f337b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "         Edit of\n",
       "             content = receit\n",
       "             edit = receipt\n",
       "             type = insert\n",
       "             edit word probaility = 1.1653078877898144e-05\n",
       "             keyboard_distance = 2\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = receit\n",
       "             edit = deceit\n",
       "             type = replace\n",
       "             edit word probaility = 3.585562731660967e-06\n",
       "             keyboard_distance = 2\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = receit\n",
       "             edit = recent\n",
       "             type = replace\n",
       "             edit word probaility = 4.750870619450781e-05\n",
       "             keyboard_distance = 4\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = list(checker.candidates(\"receit\")) # receipt\n",
    "candidates.sort(key = lambda x: checker.P(x), reverse = True)\n",
    "candidates.sort(key = lambda x: x.keyboard_distance)\n",
    "candidates.sort(key = lambda x: x.edit_type.value)\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7ea099e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 'deceit'), (0.0, 'recent'), (0.0, 'receipt')]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = list(checker.candidates(\"receit\")) # receipt\n",
    "[(edit.probability(), edit.edit) for edit in candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "09dde287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        Edit of\n",
       "            content = mre\n",
       "            edit = more\n",
       "            type = insert\n",
       "            edit word probaility = 0.001790092193781738\n",
       "            keyboard_distance = 4\n",
       "            levenshtein distance = 1\n",
       "            previous edit = \n",
       "                None\n",
       "        "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correction(\"mre\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83c2d2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = are\n",
       "             type = replace\n",
       "             edit word probaility = 0.0032538981789823275\n",
       "             keyboard_distance = 7\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = ere\n",
       "             type = replace\n",
       "             edit word probaility = 8.963906829152417e-07\n",
       "             keyboard_distance = 6\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = ire\n",
       "             type = replace\n",
       "             edit word probaility = 8.963906829152417e-07\n",
       "             keyboard_distance = 3\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = mare\n",
       "             type = insert\n",
       "             edit word probaility = 4.481953414576209e-06\n",
       "             keyboard_distance = 7\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = me\n",
       "             type = delete\n",
       "             edit word probaility = 0.0017210701111972642\n",
       "             keyboard_distance = 1\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = mere\n",
       "             type = insert\n",
       "             edit word probaility = 7.08148639503041e-05\n",
       "             keyboard_distance = 6\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = more\n",
       "             type = insert\n",
       "             edit word probaility = 0.001790092193781738\n",
       "             keyboard_distance = 4\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = mr\n",
       "             type = delete\n",
       "             edit word probaility = 0.00032270064584948705\n",
       "             keyboard_distance = 0\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = mrs\n",
       "             type = replace\n",
       "             edit word probaility = 5.288705029199927e-05\n",
       "             keyboard_distance = 2\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = ore\n",
       "             type = replace\n",
       "             edit word probaility = 2.6891720487457255e-06\n",
       "             keyboard_distance = 4\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = pre\n",
       "             type = replace\n",
       "             edit word probaility = 1.3445860243728626e-05\n",
       "             keyboard_distance = 5\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         ,\n",
       " \n",
       "         Edit of\n",
       "             content = mre\n",
       "             edit = re\n",
       "             type = delete\n",
       "             edit word probaility = 0.00016941783907098069\n",
       "             keyboard_distance = -1\n",
       "             levenshtein distance = 1\n",
       "             previous edit = \n",
       "                 None\n",
       "         }"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = checker.candidates(\"mre\") # more\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f4643f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "        Edit\n",
       "            content = ever\n",
       "            type = replace\n",
       "            previous edit = \n",
       "                None\n",
       "            keyboard_distance = 3\n",
       "        "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checker.correction(\"evar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "304027d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "         Edit\n",
       "             content = ear\n",
       "             type = delete\n",
       "             previous edit = \n",
       "                 None\n",
       "             keyboard_distance = 2\n",
       "         ,\n",
       " \n",
       "         Edit\n",
       "             content = eva\n",
       "             type = delete\n",
       "             previous edit = \n",
       "                 None\n",
       "             keyboard_distance = 0\n",
       "         ,\n",
       " \n",
       "         Edit\n",
       "             content = ever\n",
       "             type = replace\n",
       "             previous edit = \n",
       "                 None\n",
       "             keyboard_distance = 3\n",
       "         }"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = checker.candidates(\"evar\") # ever\n",
    "candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b164fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_to_open = f'big_{\"en\"}.txt'\n",
    "        \n",
    "with open(file_to_open, \"r\") as file:\n",
    "    corpus = file.read()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6e93e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def train_language_model(corpus):\n",
    "    # A function to train a trigram language model\n",
    "    model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "    for sentence in corpus:\n",
    "        sentence = sentence.split()\n",
    "\n",
    "        for w1, w2, w3 in zip(sentence[:-2], sentence[1:-1], sentence[2:]):\n",
    "            model[(w1, w2)][w3] += 1  # Increase the count each time a trigram is encountered\n",
    "\n",
    "    # Normalizing the counts to get probabilities\n",
    "    for w1_w2 in model:\n",
    "        total_count = float(sum(model[w1_w2].values()))\n",
    "        for w3 in model[w1_w2]:\n",
    "            model[w1_w2][w3] /= total_count\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9985d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(sentence, possible_words, model):\n",
    "    # A function to predict the next word using a trigram language model\n",
    "    sentence = sentence.split()\n",
    "    if len(sentence) < 2:\n",
    "        return None\n",
    "\n",
    "    w1, w2 = sentence[-2], sentence[-1]\n",
    "    probabilities = {word: model[(w1, w2)][word] for word in possible_words}\n",
    "    print(probabilities)\n",
    "    return max(probabilities, key=probabilities.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8bf8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_language_model(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b85f4004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[(\"going\", \"to\")][\"him\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a5302e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6488665"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6825cd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'to': 0, 'eavesdropping': 0, 'Anaconda': 0, 'me': 0, 'him': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(\"and according\", [\"to\", \"eavesdropping\", \"Anaconda\", \"me\", \"him\"], model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b978833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "def train_model(n, tokenized_text):\n",
    "    train_data, padded_sentences = padded_everygram_pipeline(n, tokenized_text)\n",
    "    model = Laplace(n)\n",
    "    model.fit(train_data, padded_sentences)\n",
    "    return model\n",
    "\n",
    "def predict_next_word(model, sentence, list_of_words):\n",
    "    tokenized_sentence = list(map(str.lower, nltk.word_tokenize(sentence)))\n",
    "    # Using the model's vocabulary, find the missing words not in the vocabulary and give them a score of 0\n",
    "    missing_words = set(list_of_words) - set(model.vocab)\n",
    "    scores = {word: 0 for word in missing_words}\n",
    "    \n",
    "    # For words in the model's vocabulary, estimate the probability of the next word\n",
    "    for word in model.vocab:\n",
    "        if word in list_of_words:\n",
    "            scores[word] = model.score(word, tokenized_sentence[-(model.order - 1):])\n",
    "    print(scores)\n",
    "    # Return the word with the highest probability\n",
    "    return max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3e7ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "n = 3\n",
    "tokenized_text = [list(map(str.lower, nltk.word_tokenize(sent))) for sent in corpus]\n",
    "model = train_model(n, tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d6554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'him': 0, 'eavesdropping': 0, 'to': 0, 'me': 0, 'Anaconda': 0}\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "sentence = \"I am going\"\n",
    "list_of_words = [\"to\", \"me\", \"Anaconda\", \"eavesdropping\", \"him\"]\n",
    "predicted_word = predict_next_word(model, sentence, list_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "070769be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'him'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7246129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "def predict_next_word(sentence, possible_words, n=3):\n",
    "    # split sentence into tokens\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    # create ngrams\n",
    "    grams = list(ngrams(tokens, n))\n",
    "    \n",
    "    # count ngrams\n",
    "    ngram_counts = Counter(grams)\n",
    "    preceding_bigram = tuple(tokens[-(n-1):])  # get last (n-1) words from sentence\n",
    "\n",
    "    # count preceding bigrams\n",
    "    preceding_bigram_counts = Counter({key:val for key,val in ngram_counts.items() if key[:-1] == preceding_bigram})\n",
    "    total_preceding_bigram_counts = sum(preceding_bigram_counts.values())\n",
    "\n",
    "    # get trigram probabilities\n",
    "    trigram_probabilities = {}\n",
    "    for word in possible_words:\n",
    "        trigram = preceding_bigram + (word,)\n",
    "        trigram_count = ngram_counts.get(trigram, 0) + 1  # add-one Laplace Smoothing\n",
    "        trigram_probability = trigram_count / (total_preceding_bigram_counts + len(possible_words))  # add V to denominator\n",
    "        trigram_probabilities[word] = trigram_probability\n",
    "\n",
    "    return trigram_probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6de4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
